<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Can Graph Neural Networks Be Exploited through Data-Free Model Extraction Attacks? | TAY&#39;S BLOG</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="IntroductionContributionA key innovation of STEALGNN lies in its ability to conduct model extraction without the need for access to real-world graph data  stealGNN: a poineering research endeavor that">
<meta property="og:type" content="article">
<meta property="og:title" content="Can Graph Neural Networks Be Exploited through Data-Free Model Extraction Attacks?">
<meta property="og:url" content="http://example.com/2024/09/28/Can-Graph-Neural-Networks-Be-Exploited-through-Data-Free-Model-Extraction-Attacks/index.html">
<meta property="og:site_name" content="TAY&#39;S BLOG">
<meta property="og:description" content="IntroductionContributionA key innovation of STEALGNN lies in its ability to conduct model extraction without the need for access to real-world graph data  stealGNN: a poineering research endeavor that">
<meta property="og:locale" content="zh_CH">
<meta property="article:published_time" content="2024-09-28T04:43:03.000Z">
<meta property="article:modified_time" content="2024-10-08T14:10:41.549Z">
<meta property="article:author" content="tay">
<meta property="article:tag" content="machine learning attacks">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="TAY'S BLOG" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 7.1.1"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">TAY&#39;S BLOG</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Suche"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Suche"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-Can-Graph-Neural-Networks-Be-Exploited-through-Data-Free-Model-Extraction-Attacks" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/09/28/Can-Graph-Neural-Networks-Be-Exploited-through-Data-Free-Model-Extraction-Attacks/" class="article-date">
  <time class="dt-published" datetime="2024-09-28T04:43:03.000Z" itemprop="datePublished">2024-09-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      Can Graph Neural Networks Be Exploited through Data-Free Model Extraction Attacks?
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><h2 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution"></a>Contribution</h2><p>A key innovation of STEALGNN lies in its ability to conduct model extraction without the need for access to real-world graph data</p>
<ol>
<li>stealGNN: a poineering research endeavor that addresses data-free model extraction attacks on GNN. By <strong>developing a trainable graph generator</strong>(Similar to the GAN.), stealGNN demostrates its ability to train a high-quality surrogate model from black-box GNN models, even when only hard labels are available.</li>
<li>Systematic Study: We conduct a comprehensive investigation and propose three extraction attack scenarios based on the updating scheme of the graph generator parameters. These scenarios provide a systematic understanding of different approaches within the stealGNN framework. </li>
<li>Task Flexibility: STEALGNN is highly adaptable and robust, capable of effectively handling various tasks. It can be applied to both node classification and link prediction tasks, showcasing its versatility.</li>
</ol>
<h1 id="Threat-Model"><a href="#Threat-Model" class="headerlink" title="Threat Model"></a>Threat Model</h1><h2 id="Attacker’s-Setting"><a href="#Attacker’s-Setting" class="headerlink" title="Attacker’s Setting"></a>Attacker’s Setting</h2><p>Attackers are constrained to rely on **synthetic datasets **to query the victim model and extract valuable information. The adversary can not access to the victim model’s original training data. </p>
<h2 id="Attacker’s-Goal"><a href="#Attacker’s-Goal" class="headerlink" title="Attacker’s Goal"></a>Attacker’s Goal</h2><p>(1) The attacker aims to obtain a model that achieves **comparable accuracy **to the target model. (2) The attacker attempts to replicate the **decision boundary **of the target model.</p>
<h2 id="Attacker’s-Taxonomy"><a href="#Attacker’s-Taxonomy" class="headerlink" title="Attacker’s Taxonomy"></a>Attacker’s Taxonomy</h2><ol>
<li>type 1: use the victim model and the surrogate model to compute the loss</li>
<li>type 2: only use the surrogate model to compute</li>
<li>type 3: use two surrogate model to compute</li>
</ol>
<h1 id="stealGNN"><a href="#stealGNN" class="headerlink" title="stealGNN"></a>stealGNN</h1><h2 id="Attack-Framework"><a href="#Attack-Framework" class="headerlink" title="Attack Framework"></a>Attack Framework</h2><p>featrue generate -&gt; structrue generate -&gt; a graph G</p>
<p>graph G -&gt; victim model &#x2F; surrogate model -&gt; compute the loss function based on the outputs of the victim model and the surrogate model. -&gt; update the surrogate model</p>
<p>The loss funtion can also be a measure of how well  the surrogate model  can emulate the victim model. </p>
<h2 id="Graph-Generator"><a href="#Graph-Generator" class="headerlink" title="Graph Generator"></a>Graph Generator</h2><h3 id="Feature-Generator"><a href="#Feature-Generator" class="headerlink" title="Feature Generator"></a>Feature Generator</h3><p>goal: generate the attributes of the nodes. </p>
<p>one-dimensional noise vector -&gt; two-dimensional node feature matrix F (n*d)(the number of nodes in the graph x the dimension of the node featrues). </p>
<p>q : how to decide the n and d when we don’t know the training data of the victim model.</p>
<h3 id="Structure-Generator"><a href="#Structure-Generator" class="headerlink" title="Structure Generator"></a>Structure Generator</h3><p>goal: decide whether there is a link between two nodes. generate the graph structure. </p>
<h4 id="Cosine-similarity-graph-structure-generator"><a href="#Cosine-similarity-graph-structure-generator" class="headerlink" title="Cosine similarity graph structure generator"></a>Cosine similarity graph structure generator</h4><p>We construct a similarity graph using the cosine similarity of the node feature.</p>
<p>When the values between two nodes if smaller than a given threshold t, it represents there is  no link between these two nodes. </p>
<h4 id="Full-parameterization-graph-structure-generator"><a href="#Full-parameterization-graph-structure-generator" class="headerlink" title="Full parameterization graph structure generator"></a>Full parameterization graph structure generator</h4><p>the generator disregards the input node features and directly optimizes the adjacency matrix</p>
<h2 id="Training-Surrogate-Model"><a href="#Training-Surrogate-Model" class="headerlink" title="Training Surrogate Model"></a>Training Surrogate Model</h2><p>generated graph G is used to query victim model and surrogate model. </p>
<p>The surrogate mdoel paramenters are updated using the cross-entropy loss functim to minimize the discrepancy between the output of the victim model and surrogate model, so that we can extract the knowledge embedded in victim model. </p>
<h2 id="Training-Graph-Generator"><a href="#Training-Graph-Generator" class="headerlink" title="Training Graph Generator"></a>Training Graph Generator</h2><p>The generator model  is  trained to maximize the disagreement between the predictions of the victim model and the surrogate model. </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/09/28/Can-Graph-Neural-Networks-Be-Exploited-through-Data-Free-Model-Extraction-Attacks/" data-id="cm2vmjb9w001kwwtg1yf53ob1" data-title="Can Graph Neural Networks Be Exploited through Data-Free Model Extraction Attacks?" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning-attacks/" rel="tag">machine learning attacks</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2024/10/06/poison-attack-in-inductive-GNN/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Neuer</strong>
      <div class="article-nav-title">
        
          poison attack in inductive GNN
        
      </div>
    </a>
  
  
    <a href="/2024/09/23/Link-Stealing-Attacks-Against-Inductive-GNN/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Älter</strong>
      <div class="article-nav-title">Link Stealing Attacks Against Inductive GNN</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/algorithm-template/" rel="tag">algorithm-template</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/attacks/" rel="tag">attacks</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ctf/" rel="tag">ctf</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ctf-misc/" rel="tag">ctf-misc</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/encryption/" rel="tag">encryption</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/learning/" rel="tag">learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/machine/" rel="tag">machine</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/machine-learning/" rel="tag">machine learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/machine-learning-attacks/" rel="tag">machine learning attacks</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/" rel="tag">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tip/" rel="tag">tip</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BF%9D%E7%A0%94/" rel="tag">保研</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%AF%8F%E6%97%A5%E4%B8%80%E5%B0%8F%E7%BB%93/" rel="tag">每日一小结</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/algorithm-template/" style="font-size: 10px;">algorithm-template</a> <a href="/tags/attacks/" style="font-size: 10px;">attacks</a> <a href="/tags/ctf/" style="font-size: 20px;">ctf</a> <a href="/tags/ctf-misc/" style="font-size: 14px;">ctf-misc</a> <a href="/tags/encryption/" style="font-size: 14px;">encryption</a> <a href="/tags/learning/" style="font-size: 10px;">learning</a> <a href="/tags/machine/" style="font-size: 10px;">machine</a> <a href="/tags/machine-learning/" style="font-size: 16px;">machine learning</a> <a href="/tags/machine-learning-attacks/" style="font-size: 16px;">machine learning attacks</a> <a href="/tags/python/" style="font-size: 14px;">python</a> <a href="/tags/tip/" style="font-size: 12px;">tip</a> <a href="/tags/%E4%BF%9D%E7%A0%94/" style="font-size: 10px;">保研</a> <a href="/tags/%E6%AF%8F%E6%97%A5%E4%B8%80%E5%B0%8F%E7%BB%93/" style="font-size: 18px;">每日一小结</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archiv</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/10/">October 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/09/">September 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/08/">August 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/07/">July 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/06/">June 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/05/">May 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/04/">April 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/03/">March 2024</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">letzter Beitrag</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2024/10/30/Rethinking-Graph-Backdoor-Attacks-A-Distribution-Preserving-Perspective/">Rethinking Graph Backdoor Attacks: A Distribution-Preserving Perspective</a>
          </li>
        
          <li>
            <a href="/2024/10/22/24%E4%BF%9D%E7%A0%94%E5%88%86%E4%BA%AB/">24保研分享</a>
          </li>
        
          <li>
            <a href="/2024/10/09/graph-backdoor/">graph backdoor</a>
          </li>
        
          <li>
            <a href="/2024/10/08/Poisoning-Graph-Neural-Networks-for-Link-Inference/">Poisoning Graph Neural Networks for Link Inference</a>
          </li>
        
          <li>
            <a href="/2024/10/06/poison-attack-in-inductive-GNN/">poison attack in inductive GNN</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2024 tay<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>