<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>TAY&#39;S BLOG</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="TAY&#39;S BLOG">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="TAY&#39;S BLOG">
<meta property="og:locale" content="zh_CH">
<meta property="article:author" content="tay">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="TAY'S BLOG" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 7.1.1"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">TAY&#39;S BLOG</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Suche"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Suche"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-poison-attack-in-inductive-GNN" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/10/06/poison-attack-in-inductive-GNN/" class="article-date">
  <time class="dt-published" datetime="2024-10-06T13:41:15.000Z" itemprop="datePublished">2024-10-06</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/10/06/poison-attack-in-inductive-GNN/">poison attack in inductive GNN</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p> 通过改边&#x2F;改点的方式，影响点分类和图分类任务的成功率，达到中毒攻击的目的。</p>
<p>看论文重点：如何改边，如何改点（深层：GNN模型是如何训练出来的，看它是如何学习到边&#x2F;点的特征的</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/10/06/poison-attack-in-inductive-GNN/" data-id="cm1xui44z003sd8tg69ccfv87" data-title="poison attack in inductive GNN" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning-attacks/" rel="tag">machine learning attacks</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-Can-Graph-Neural-Networks-Be-Exploited-through-Data-Free-Model-Extraction-Attacks" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/09/28/Can-Graph-Neural-Networks-Be-Exploited-through-Data-Free-Model-Extraction-Attacks/" class="article-date">
  <time class="dt-published" datetime="2024-09-28T04:43:03.000Z" itemprop="datePublished">2024-09-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/09/28/Can-Graph-Neural-Networks-Be-Exploited-through-Data-Free-Model-Extraction-Attacks/">Can Graph Neural Networks Be Exploited through Data-Free Model Extraction Attacks?</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><h2 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution"></a>Contribution</h2><p>A key innovation of STEALGNN lies in its ability to conduct model extraction without the need for access to real-world graph data</p>
<ol>
<li>stealGNN: a poineering research endeavor that addresses data-free model extraction attacks on GNN. By <strong>developing a trainable graph generator</strong>(Similar to the GAN.), stealGNN demostrates its ability to train a high-quality surrogate model from black-box GNN models, even when only hard labels are available.</li>
<li>Systematic Study: We conduct a comprehensive investigation and propose three extraction attack scenarios based on the updating scheme of the graph generator parameters. These scenarios provide a systematic understanding of different approaches within the stealGNN framework. </li>
<li>Task Flexibility: STEALGNN is highly adaptable and robust, capable of effectively handling various tasks. It can be applied to both node classification and link prediction tasks, showcasing its versatility.</li>
</ol>
<h1 id="Threat-Model"><a href="#Threat-Model" class="headerlink" title="Threat Model"></a>Threat Model</h1><h2 id="Attacker’s-Setting"><a href="#Attacker’s-Setting" class="headerlink" title="Attacker’s Setting"></a>Attacker’s Setting</h2><p>Attackers are constrained to rely on **synthetic datasets **to query the victim model and extract valuable information. The adversary can not access to the victim model’s original training data. </p>
<h2 id="Attacker’s-Goal"><a href="#Attacker’s-Goal" class="headerlink" title="Attacker’s Goal"></a>Attacker’s Goal</h2><p>(1) The attacker aims to obtain a model that achieves **comparable accuracy **to the target model. (2) The attacker attempts to replicate the **decision boundary **of the target model.</p>
<h2 id="Attacker’s-Taxonomy"><a href="#Attacker’s-Taxonomy" class="headerlink" title="Attacker’s Taxonomy"></a>Attacker’s Taxonomy</h2><ol>
<li>type 1: use the victim model and the surrogate model to compute the loss</li>
<li>type 2: only use the surrogate model to compute</li>
<li>type 3: use two surrogate model to compute</li>
</ol>
<h1 id="stealGNN"><a href="#stealGNN" class="headerlink" title="stealGNN"></a>stealGNN</h1><h2 id="Attack-Framework"><a href="#Attack-Framework" class="headerlink" title="Attack Framework"></a>Attack Framework</h2><p>featrue generate -&gt; structrue generate -&gt; a graph G</p>
<p>graph G -&gt; victim model &#x2F; surrogate model -&gt; compute the loss function based on the outputs of the victim model and the surrogate model. -&gt; update the surrogate model</p>
<p>The loss funtion can also be a measure of how well  the surrogate model  can emulate the victim model. </p>
<h2 id="Graph-Generator"><a href="#Graph-Generator" class="headerlink" title="Graph Generator"></a>Graph Generator</h2><h3 id="Feature-Generator"><a href="#Feature-Generator" class="headerlink" title="Feature Generator"></a>Feature Generator</h3><p>goal: generate the attributes of the nodes. </p>
<p>one-dimensional noise vector -&gt; two-dimensional node feature matrix F (n*d)(the number of nodes in the graph x the dimension of the node featrues). </p>
<p>q : how to decide the n and d when we don’t know the training data of the victim model.</p>
<h3 id="Structure-Generator"><a href="#Structure-Generator" class="headerlink" title="Structure Generator"></a>Structure Generator</h3><p>goal: decide whether there is a link between two nodes. generate the graph structure. </p>
<h4 id="Cosine-similarity-graph-structure-generator"><a href="#Cosine-similarity-graph-structure-generator" class="headerlink" title="Cosine similarity graph structure generator"></a>Cosine similarity graph structure generator</h4><p>We construct a similarity graph using the cosine similarity of the node feature.</p>
<p>When the values between two nodes if smaller than a given threshold t, it represents there is  no link between these two nodes. </p>
<h4 id="Full-parameterization-graph-structure-generator"><a href="#Full-parameterization-graph-structure-generator" class="headerlink" title="Full parameterization graph structure generator"></a>Full parameterization graph structure generator</h4>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/09/28/Can-Graph-Neural-Networks-Be-Exploited-through-Data-Free-Model-Extraction-Attacks/" data-id="cm1xui44j001cd8tgdljkg3gs" data-title="Can Graph Neural Networks Be Exploited through Data-Free Model Extraction Attacks?" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning-attacks/" rel="tag">machine learning attacks</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-Link-Stealing-Attacks-Against-Inductive-GNN" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/09/23/Link-Stealing-Attacks-Against-Inductive-GNN/" class="article-date">
  <time class="dt-published" datetime="2024-09-23T07:14:09.000Z" itemprop="datePublished">2024-09-23</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/09/23/Link-Stealing-Attacks-Against-Inductive-GNN/">Link Stealing Attacks Against Inductive GNN</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>The core idea of GNN is to leverage neighbor informatin among nodes to obtain node embeddings.</p>
<p>Two settings for GNNs: the  transductive setting and the inductive setting.</p>
<p>Two types of link stealing attacks:the posterior-only attack,the combined attack</p>
<p>Goal:given a node  pair in the target training graph , the adversary’s goal is to infer whether there exists a link between these two nodes. </p>
<h1 id="Our-Attacks"><a href="#Our-Attacks" class="headerlink" title="Our Attacks"></a>Our Attacks</h1><h2 id="Threat-Model"><a href="#Threat-Model" class="headerlink" title="Threat Model"></a>Threat Model</h2><h3 id="Adversary’s-Background-Knowledge"><a href="#Adversary’s-Background-Knowledge" class="headerlink" title="Adversary’s Background Knowledge"></a>Adversary’s Background Knowledge</h3><p>To obtain the posteriors of v, the adversary needs to construct gkv that contains node attributes and graph structures. </p>
<p>Using shadow dataset to train shadow model to mimic the train model.</p>
<h3 id="Posterior-Only-Attacks"><a href="#Posterior-Only-Attacks" class="headerlink" title="Posterior-Only Attacks"></a>Posterior-Only Attacks</h3><p>This type of attack only uses the posteriors of the node pair (u, v) obtained from the GNN models to design attack input features.</p>
<h3 id="Combined-Attacks"><a href="#Combined-Attacks" class="headerlink" title="Combined Attacks"></a>Combined Attacks</h3><p>We propose combined attacks that combine posteriors with traditional link prediction features, i.e., node attributes and graph features.</p>
<h2 id="Attack-Methodology"><a href="#Attack-Methodology" class="headerlink" title="Attack Methodology"></a>Attack Methodology</h2><h3 id="Shadow-Model-Training"><a href="#Shadow-Model-Training" class="headerlink" title="Shadow Model Training"></a>Shadow Model Training</h3><h3 id="Attack-Model-Training"><a href="#Attack-Model-Training" class="headerlink" title="Attack Model Training"></a>Attack Model Training</h3><p>The attack  model is a binary classifier that can predict if two given nodes have a connection in target training dataset. (Output is 1&#x2F;0). </p>
<p>Specifically, we follow the strategy in [15] and leverage four pairwise, commutative operations to ensure attack input features are the same even if nodes are presented in a different order for the given pair.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/09/23/Link-Stealing-Attacks-Against-Inductive-GNN/" data-id="cm1xui44k001gd8tggr9whdu5" data-title="Link Stealing Attacks Against Inductive GNN" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning-attacks/" rel="tag">machine learning attacks</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-深度学习代码：Narcissus-tensflow" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/08/09/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%BB%A3%E7%A0%81%EF%BC%9ANarcissus-tensflow/" class="article-date">
  <time class="dt-published" datetime="2024-08-09T15:34:15.000Z" itemprop="datePublished">2024-08-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/08/09/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%BB%A3%E7%A0%81%EF%BC%9ANarcissus-tensflow/">深度学习代码：Narcissus/tensorflow</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="Epoch-Batch-Size-Iteration"><a href="#Epoch-Batch-Size-Iteration" class="headerlink" title="Epoch&#x2F;Batch Size&#x2F;Iteration"></a>Epoch&#x2F;Batch Size&#x2F;Iteration</h1><h2 id="Epoch"><a href="#Epoch" class="headerlink" title="Epoch"></a>Epoch</h2><p>一个<strong>完整</strong>的数据集通过了神经网络一次并返回了一次</p>
<h2 id="Batch-Size"><a href="#Batch-Size" class="headerlink" title="Batch Size"></a>Batch Size</h2><p>一个batch中的样本总量</p>
<h2 id="Iteration"><a href="#Iteration" class="headerlink" title="Iteration"></a>Iteration</h2><p>一个batch需要完成一个epoch的次数</p>
<p>比如对于一个有 2000 个训练样本的数据集。将 2000 个样本分成4个500的batch size，那么完成一个 epoch 需要 4 个 iteration。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/08/09/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%BB%A3%E7%A0%81%EF%BC%9ANarcissus-tensflow/" data-id="cm1xui4510040d8tg5hjcav6w" data-title="深度学习代码：Narcissus/tensorflow" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning/" rel="tag">machine learning</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-Stealing Links from GNN" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/07/12/Stealing%20Links%20from%20GNN/" class="article-date">
  <time class="dt-published" datetime="2024-07-12T07:01:15.000Z" itemprop="datePublished">2024-07-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/07/12/Stealing%20Links%20from%20GNN/">Stealing Links from GNN</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><h2 id="Our-Contributions"><a href="#Our-Contributions" class="headerlink" title="Our Contributions"></a>Our Contributions</h2><p>Given a black-box access to a target GNN model, our attacks aim to predict whether there exists a link between any pair of nodes in the gragh used to train the target GNN model.</p>
<h2 id="Background-knowledge"><a href="#Background-knowledge" class="headerlink" title="Background knowledge"></a>Background knowledge</h2><p>Three dimensions: the target dataset’s nodes’ attributes, the target dataset’s partial gragh, and an auxiliaty dataset(called shadow dataset) which also contains its own gragh and nodes’ attributes.</p>
<h2 id="Attacks-Methodology"><a href="#Attacks-Methodology" class="headerlink" title="Attacks Methodology"></a>Attacks Methodology</h2><p>The key intuition of our attacks: two nodes are more likely to be linked if they share more similat attributes and&#x2F;or predictions from the target GNN model.</p>
<h1 id="Gragh-Neural-Networks"><a href="#Gragh-Neural-Networks" class="headerlink" title="Gragh Neural Networks"></a>Gragh Neural Networks</h1><h2 id="training"><a href="#training" class="headerlink" title="training"></a>training</h2><p>Given a graph, attributes for each node in the graph, and a small number of labeled nodes, GNN trains a neural network to predict labels of the remaining unlabeled nodes via analyzing the graph structure and node attributes.</p>
<h2 id="Prediction"><a href="#Prediction" class="headerlink" title="Prediction"></a>Prediction</h2><p>Since all nodes’ attributes and the whole graph have been fed into the GNN model in the training phase to predict the label of a node, we only need to provide the node’s ID to the trained model and obtain the prediction result.</p>
<h1 id="Problem-Formulation"><a href="#Problem-Formulation" class="headerlink" title="Problem Formulation"></a>Problem Formulation</h1><h2 id="Threat-Model"><a href="#Threat-Model" class="headerlink" title="Threat Model"></a>Threat Model</h2><h3 id="Adversary’s-Goal"><a href="#Adversary’s-Goal" class="headerlink" title="Adversary’s Goal"></a>Adversary’s Goal</h3><p>Infering whether a given pair of nodes are connected in the target dataset.</p>
<h3 id="Adversary’s-Background-Knowledge"><a href="#Adversary’s-Background-Knowledge" class="headerlink" title="Adversary’s Background Knowledge"></a>Adversary’s Background Knowledge</h3><ol>
<li>Target Dataset’s Nodes’ Attributes</li>
<li>Target Dataset’s Partial Graph</li>
<li>A Shadow Dataset</li>
</ol>
<h2 id="Link-Stealing-Attack"><a href="#Link-Stealing-Attack" class="headerlink" title="Link Stealing Attack"></a>Link Stealing Attack</h2><p>Given a black-box access to a GNN model that is trained on a target dataset, a pair of nodes u and v in the target dataset, and an adversary’s background knowledge K , link stealing attack aims to infer whether there is a link between u and v in the target dataset.</p>
<h1 id="Attack-Taxonomy"><a href="#Attack-Taxonomy" class="headerlink" title="Attack Taxonomy"></a>Attack Taxonomy</h1><p>Two problem: </p>
<ol>
<li><p>As we consider undirected gragh, the output should be the same regardless of the input node pair order.</p>
</li>
<li><p>The shadow dataset and the target dataset normally have different dimensions with respect to attributes and posteriors. It is crucial to keep the attack model’s input features’ dimension consistent no matter which shadow dataset she has during the transferring attacks.</p>
</li>
</ol>
<h2 id="Attack-Methodologies"><a href="#Attack-Methodologies" class="headerlink" title="Attack Methodologies"></a>Attack Methodologies</h2><img src="C:\Users\梁韵扬\AppData\Local\Temp\1eedd3d4-adb7-40b8-af29-2efefaddfff9.png" alt="1eedd3d4-adb7-40b8-af29-2efefaddfff9" style="zoom:67%;" />

<h3 id="Attack-0-Attack-2"><a href="#Attack-0-Attack-2" class="headerlink" title="Attack-0,Attack-2"></a>Attack-0,Attack-2</h3><p>The adversary can use distance metrics for posteriors or nodes’ attributes to infer the link.</p>
<h3 id="Attack-3-Attack-6"><a href="#Attack-3-Attack-6" class="headerlink" title="Attack-3,Attack-6"></a>Attack-3,Attack-6</h3><p>The adversary can use different distances and pairwise vector operations over nodes’ posteriors (and the corresponding entropies) from the target model and their attributes to build features.</p>
<h3 id="Attack-1-Attack-4-Attack-5-Attack-7"><a href="#Attack-1-Attack-4-Attack-5-Attack-7" class="headerlink" title="Attack-1,Attack-4,Attack-5,Attack-7"></a>Attack-1,Attack-4,Attack-5,Attack-7</h3><p>The adversary can use distance metrics over posteriors&#x2F;nodes’ attributes and pairwise operations over posteriors’ entropies as the bridge to transfer the knowledge from the shadow dataset to perform link stealing attacks.</p>
<p>​    </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/07/12/Stealing%20Links%20from%20GNN/" data-id="cm1xui44n001ud8tgbh304h4w" data-title="Stealing Links from GNN" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning-attacks/" rel="tag">machine learning attacks</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-Encrypted-Video-Search" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/07/09/Encrypted-Video-Search/" class="article-date">
  <time class="dt-published" datetime="2024-07-09T03:45:14.000Z" itemprop="datePublished">2024-07-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/07/09/Encrypted-Video-Search/">Encrypted Video Search</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><h2 id="Goal"><a href="#Goal" class="headerlink" title="Goal"></a>Goal</h2><p>Aiming at an encrypted video search framework from only lightweight cryptography: Scalability, content-based similarity, Modular design</p>
<h2 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution"></a>Contribution</h2><ol>
<li><p>Our framework is generic for integrating different up-to-date primitives. It is optimal in search time and incurs small storage at the server.</p>
</li>
<li><p>We formalize the syntax of our framework in a modular fashion and prove the adaptive security.</p>
</li>
<li><p>To balance efficiency and security, we present two concrete instantiations. We conduct experiments over real-world datasets to show the efficiency, accuracy, and practicality.</p>
</li>
</ol>
<img src="C:\Users\梁韵扬\AppData\Local\Temp\f11ab940-eefa-4a5c-b172-a0b8ac9b6f44.png" alt="f11ab940-eefa-4a5c-b172-a0b8ac9b6f44" style="zoom:67%;" />

<img src="C:\Users\梁韵扬\AppData\Local\Temp\79d5975d-659f-49ee-845c-262d9f8131ed.png" alt="79d5975d-659f-49ee-845c-262d9f8131ed" style="zoom:67%;" />

<h1 id="Modularization-and-Ingredients"><a href="#Modularization-and-Ingredients" class="headerlink" title="Modularization and Ingredients"></a>Modularization and Ingredients</h1><h2 id="Video-Preprocessing-and-setup"><a href="#Video-Preprocessing-and-setup" class="headerlink" title="Video Preprocessing and setup"></a>Video Preprocessing and setup</h2><img src="C:\Users\梁韵扬\AppData\Local\Temp\b50a6917-5b1e-482c-872b-0363fdeab34c.png" alt="b50a6917-5b1e-482c-872b-0363fdeab34c" style="zoom: 67%;" />

<img src="C:\Users\梁韵扬\AppData\Local\Temp\f93c6952-5570-4072-a6d5-10c858c53b7b.png" alt="f93c6952-5570-4072-a6d5-10c858c53b7b" style="zoom: 50%;" />

<h2 id="Hierarchial-Search"><a href="#Hierarchial-Search" class="headerlink" title="Hierarchial Search"></a>Hierarchial Search</h2><img src="C:\Users\梁韵扬\AppData\Local\Temp\a2ec30c9-cec5-4abe-bad6-086b28098c5a.png" alt="a2ec30c9-cec5-4abe-bad6-086b28098c5a" style="zoom:67%;" />

<h2 id="Ranking-with-Similarity"><a href="#Ranking-with-Similarity" class="headerlink" title="Ranking with Similarity"></a>Ranking with Similarity</h2><img src="C:\Users\梁韵扬\AppData\Local\Temp\7ca4c107-540a-4d29-b0a8-1be8e98d100d.png" alt="7ca4c107-540a-4d29-b0a8-1be8e98d100d" style="zoom:67%;" />

<h2 id="Databse-Update-with-dynamic-Security"><a href="#Databse-Update-with-dynamic-Security" class="headerlink" title="Databse Update with dynamic Security"></a>Databse Update with dynamic Security</h2><img src="C:\Users\梁韵扬\AppData\Local\Temp\76a9db27-db95-488d-a6e1-a85b9c36dff6.png" alt="76a9db27-db95-488d-a6e1-a85b9c36dff6" style="zoom:67%;" />

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/07/09/Encrypted-Video-Search/" data-id="cm1xui44j001fd8tgh631hlc0" data-title="Encrypted Video Search" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/encryption/" rel="tag">encryption</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-Backdoor-Attack" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/07/06/Backdoor-Attack/" class="article-date">
  <time class="dt-published" datetime="2024-07-06T10:04:36.000Z" itemprop="datePublished">2024-07-06</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/07/06/Backdoor-Attack/">Backdoor Attack</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p><strong>Backdoor Attack</strong>:Inject some attacker-specified patterns in the poisoned iamge and replace the corresponding label with a pre-defined target label.</p>
<h1 id="Invisible-Backdoor-Attack-with-Sample-Specific-Triggers"><a href="#Invisible-Backdoor-Attack-with-Sample-Specific-Triggers" class="headerlink" title="Invisible Backdoor Attack with Sample-Specific Triggers"></a>Invisible Backdoor Attack with Sample-Specific Triggers</h1><h1 id="Contributions"><a href="#Contributions" class="headerlink" title="Contributions"></a>Contributions</h1><p>1.We reveal that the current main-stream backdoor defences all relies on a prerequisite that backdoor triggers are sample-agnostic.</p>
<p>2.We explore a novel invisible attack paradigm, where the backdoor trigger is sample-specific and invisible.</p>
<p>3.Extensive experiments are conducted, which verify the effectiveness of the proposed method.</p>
<h1 id="SSBA"><a href="#SSBA" class="headerlink" title="SSBA"></a>SSBA</h1><h2 id="Threat-Model"><a href="#Threat-Model" class="headerlink" title="Threat Model"></a>Threat Model</h2><h3 id="Attacker’s-Capacities"><a href="#Attacker’s-Capacities" class="headerlink" title="Attacker’s Capacities"></a>Attacker’s Capacities</h3><p>We assume that attackers are allowed to poison some training data, whereas they have no information on or change other training components.In the inference process, attackers can and only can query the trained model with any image.</p>
<h3 id="Attacker’s-Goal"><a href="#Attacker’s-Goal" class="headerlink" title="Attacker’s Goal"></a>Attacker’s Goal</h3><p>In general, backdoor attackers intend to embed hidden backdoors in DNNs through data poisoning.Three main goal :effectiveness, stealthiness, and sustainability.</p>
<h2 id="The-Proposed-Attack"><a href="#The-Proposed-Attack" class="headerlink" title="The Proposed Attack"></a>The Proposed Attack</h2><h3 id="The-Main-Process-of-Backdoor-Attacks"><a href="#The-Main-Process-of-Backdoor-Attacks" class="headerlink" title="The Main Process of Backdoor Attacks"></a>The Main Process of Backdoor Attacks</h3><p>Core: generate the poisoned training data set</p>
<p> <img src="C:\Users\梁韵扬\AppData\Local\Temp\aaeb1d75-58c2-49b0-b1ef-e43f44e29276.png" alt="aaeb1d75-58c2-49b0-b1ef-e43f44e29276"></p>
<img src="C:\Users\梁韵扬\AppData\Local\Temp\f3c6db4b-bb72-4ee2-9459-f5eb2b4c192f.png" alt="f3c6db4b-bb72-4ee2-9459-f5eb2b4c192f" style="zoom: 80%;" />

<h1 id="Narcissus-A-Practical-Clean-Label-Backdoor-Attack-with-Limited-Information"><a href="#Narcissus-A-Practical-Clean-Label-Backdoor-Attack-with-Limited-Information" class="headerlink" title="Narcissus: A Practical Clean-Label Backdoor Attack with Limited Information"></a>Narcissus: A Practical Clean-Label Backdoor Attack with Limited Information</h1><img src="C:\Users\梁韵扬\AppData\Local\Temp\d25dff5b-4627-4645-a4e9-0ebb4ab6d26b.png" alt="d25dff5b-4627-4645-a4e9-0ebb4ab6d26b" style="zoom: 80%;" />

<img src="C:\Users\梁韵扬\AppData\Local\Temp\38845f87-529c-47ed-ae64-cd66967c6f29.png" alt="38845f87-529c-47ed-ae64-cd66967c6f29"  />

<img src="C:\Users\梁韵扬\AppData\Local\Temp\c272ab46-34ba-46f2-95da-686fe5279e55.png" alt="c272ab46-34ba-46f2-95da-686fe5279e55" style="zoom:80%;" />

<h1 id="Contributions-1"><a href="#Contributions-1" class="headerlink" title="Contributions"></a>Contributions</h1><p>1.We present a clean-label backdoor attack that leverages only target-class and public out-of-distribution data, controlling 0.05% or even fewer data.</p>
<p>2.We compare Narcissus with existing attacks and show that it significantly outperforms others despite using less attacker knowledge and less obvious perturbations.</p>
<p>3.We demonstrate that by adapting the trigger to real-world conditions, Narcissus enables first of its kind successful physical world clean-label attacks.</p>
<p>4.We show that several popular choices of defenses and stateof-the-art ones, cannot reliably mitigate our attack. We find our triggers exhibit features that are resistant to removal.</p>
<h1 id="Clean-label-Backdoor-Attacks"><a href="#Clean-label-Backdoor-Attacks" class="headerlink" title="Clean-label Backdoor Attacks"></a>Clean-label Backdoor Attacks</h1><h2 id="Contributions-2"><a href="#Contributions-2" class="headerlink" title="Contributions"></a>Contributions</h2><p>We develop a new approach to synthesizing poisoned inputs that appear plausible to humans. Our approach consists of making small changes to the inputs in order to make them harder to classify , keeping the changes sufficiently minor in order to ensure that the original label remains plausible. We have two methods to perform it.</p>
<ol>
<li><p>GAN-based interpolation</p>
</li>
<li><p>Adversarial perturbations</p>
</li>
</ol>
<h2 id="Previous-Backdoor-Attack"><a href="#Previous-Backdoor-Attack" class="headerlink" title="Previous Backdoor Attack"></a>Previous Backdoor Attack</h2><p>We argue that the main reason for the attack’s ineffectiveness is that the poisoned samples can be correctly classified by learning a standard classifier. Since relying on the backdoor trigger is not necessary to correctly classify these inputs, the backdoor attack is unlikely to be successful.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/07/06/Backdoor-Attack/" data-id="cm1xui44i0018d8tg5hnd5nxt" data-title="Backdoor Attack" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning-attacks/" rel="tag">machine learning attacks</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-Model-Stealing" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/07/06/Model-Stealing/" class="article-date">
  <time class="dt-published" datetime="2024-07-06T07:57:34.000Z" itemprop="datePublished">2024-07-06</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/07/06/Model-Stealing/">Model Stealing</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>Formal model stealing</p>
<p><img src="C:\Users\梁韵扬\AppData\Local\Temp\0003d5ef-cf56-4605-91c5-e81b7c6d19f0.png" alt="0003d5ef-cf56-4605-91c5-e81b7c6d19f0"></p>
<p>data-free model stealing<img src="C:\Users\梁韵扬\AppData\Local\Temp\74d6f4d8-6993-4a01-bc65-3cfb68ce3dcb.png" alt="74d6f4d8-6993-4a01-bc65-3cfb68ce3dcb"></p>
<p>similar to GAN</p>
<p>use <strong>zeroth-order gradient estimation</strong> to approximate the gradient of the loss function LG.In black-box model we can’t comput the gradient directly so we use <strong>zeroth-order gradient estimation</strong> to comput the gradient indirectly by using the output of the model.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/07/06/Model-Stealing/" data-id="cm1xui44k001id8tg8q553pwz" data-title="Model Stealing" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning-attacks/" rel="tag">machine learning attacks</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-SEISA" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/06/27/SEISA/" class="article-date">
  <time class="dt-published" datetime="2024-06-27T11:54:28.000Z" itemprop="datePublished">2024-06-27</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/06/27/SEISA/">SEISA</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="introduction"><a href="#introduction" class="headerlink" title="introduction"></a>introduction</h1><h2 id="Practical-problem"><a href="#Practical-problem" class="headerlink" title="Practical problem"></a>Practical problem</h2><p>Many organizations currently prefer to host their data and services on public cloud platforms, but it will cause privacy breaches and evenn legal issues.</p>
<h2 id="Past-solutions"><a href="#Past-solutions" class="headerlink" title="Past solutions"></a>Past solutions</h2><p>1.Design over encrypted datasets by utilizing order preserving encryption (maintains the order of plaintext data in its encrypted form) and Min-Hashf (a probabilistic algorithm used to estimate the similarity between large sets).</p>
<p>drawback:</p>
<p>Only suitable for image search algorithm based on visual words representation of images and performed low search accuracy.</p>
<p>2.Based on homomorphic encryption.</p>
<p>drawback:</p>
<p>High accuracy but more cost and also need frequent user engagement.</p>
<h2 id="Challenges"><a href="#Challenges" class="headerlink" title="Challenges"></a>Challenges</h2><p>efficiency</p>
<p>accuracy</p>
<p>search access control:</p>
<p>Existing secure image search techniques and access control techniques have different encryption mechanisms.</p>
<h2 id="Goal"><a href="#Goal" class="headerlink" title="Goal"></a>Goal</h2><p>Design a lightweight encryption tool that makes search operations over ciphertexts have the same complexity as searches over plaintexts and can support search access control.</p>
<h2 id="Summarize"><a href="#Summarize" class="headerlink" title="Summarize"></a>Summarize</h2><p><strong>SEISA</strong>:</p>
<p>A secure and efficient image search scheme over encrypted dataset with access control .</p>
<h3 id="Advantage"><a href="#Advantage" class="headerlink" title="Advantage"></a>Advantage</h3><p>The search access control doesn’t need additional authorizing steps. </p>
<p>High efficiency and accuracy</p>
<h3 id="Measure"><a href="#Measure" class="headerlink" title="Measure"></a>Measure</h3><p>1.Using matrix based encryption design and encrypt image features based on the vector space model for high efficiency and accuracy.</p>
<p>2.Design an efficient tree-based index construction by utilizing the k-means clustering algorithm for efficiency.</p>
<p>3.Propose a secure k-means outsourcing algorithm ,which allows the data owner to delegate most computational tasks to the cloud.</p>
<p>4.Achieve search access control by desingning a novel and lightweight polynommial based access policy.</p>
<p>[3] [4] can be used as independent rools for other related fields.</p>
<h3 id="Verification"><a href="#Verification" class="headerlink" title="Verification"></a>Verification</h3><p>Implemented a prototype of SEISA on Amazon EC2 cloud over 10 million images.</p>
<h1 id="Backgrounds-And-Preliminarise"><a href="#Backgrounds-And-Preliminarise" class="headerlink" title="Backgrounds And Preliminarise"></a>Backgrounds And Preliminarise</h1><h2 id="Background-of-Image-Search"><a href="#Background-of-Image-Search" class="headerlink" title="Background of Image Search"></a>Background of Image Search</h2><p>BOF:</p>
<p>Assign image descriptors into visual words and then compress them into a binary vector.</p>
<p>Fisher vector:</p>
<p>more accuracy than BOF.In this work,we use fisher vector to extract image descriptor vectors.</p>
<h2 id="Mean-Average-Precision"><a href="#Mean-Average-Precision" class="headerlink" title="Mean Average Precision"></a>Mean Average Precision</h2><p>It is a way to measure the search accuracy of image search .</p>
<h1 id="System-Model-And-Threat-Model"><a href="#System-Model-And-Threat-Model" class="headerlink" title="System Model And Threat Model"></a>System Model And Threat Model</h1><h2 id="System-Model"><a href="#System-Model" class="headerlink" title="System Model"></a>System Model</h2><p>three major entities: </p>
<p>the cloud server, the data owner and users.</p>
<h2 id="Threat-Model"><a href="#Threat-Model" class="headerlink" title="Threat Model"></a>Threat Model</h2><p>cloud server : curious but honest </p>
<p>Preventing the cloud server from learning the following information: 1) Privacy of all images and their corresponding descriptor vectors; 2) Privacy of all search images from search requests; 3) Privacy of all data associated with the index construction; 4) Query unlinkability, attackers should not be able to tell whether or not two or more search are from the same search image.</p>
<h3 id="Known-Ciphertext-Model"><a href="#Known-Ciphertext-Model" class="headerlink" title="Known Ciphertext Model"></a>Known Ciphertext Model</h3><p>encrypted images and corresponding descriptor vectors, encrypted searchable index construction, encrypted search requests.</p>
<h3 id="Known-Background-Model"><a href="#Known-Background-Model" class="headerlink" title="Known Background Model"></a>Known Background Model</h3><p>A stronger threat model and may extract the statistical information of a specific encrypted image in the dataset. </p>
<h1 id="Our-Construction"><a href="#Our-Construction" class="headerlink" title="Our  Construction"></a>Our  Construction</h1><h2 id="Construction-of-SEIS"><a href="#Construction-of-SEIS" class="headerlink" title="Construction  of  SEIS"></a>Construction  of  SEIS</h2>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/06/27/SEISA/" data-id="cm1xui44m001sd8tgewehfpz8" data-title="SEISA" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/encryption/" rel="tag">encryption</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-Membership-Inference-Attacks-Against-Machine-Learning-Models" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/06/27/Membership-Inference-Attacks-Against-Machine-Learning-Models/" class="article-date">
  <time class="dt-published" datetime="2024-06-27T11:39:06.000Z" itemprop="datePublished">2024-06-27</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/06/27/Membership-Inference-Attacks-Against-Machine-Learning-Models/">Membership Inference Attacks Against Machine Learning Models</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>1.<strong>Membership inference attack</strong>: given a data record and black-box access to a model,determine if the record was in the model’s training dataset.</p>
<p>2.Train our own inference model to recoginze differences in the target model’s predictions on the inputs that it trained on versus the inputs that it did not train on</p>
<p>3.Some models cen be vulnerable to membership inference attacks.We then investigate the factors that influence this leakage and evaluate mitigation strategies.</p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>The intenet giants offering “machine learning as a service” to the customer in possession of a dataset and a data classification task.And the dataset is usually made by the activities of individual users.</p>
<h2 id="Our-contributions"><a href="#Our-contributions" class="headerlink" title="Our contributions"></a>Our contributions</h2><p>Quanitify membership information leakage through the prediction outputs of machine learning models.</p>
<p>We turn machine learning against itself and train an attack model whose purpose is to distinguish the target model’s behavior on the training inputs from its behavior on the inputs that it did not encounter during training.<strong>turn this problem into a classification problem.</strong></p>
<h1 id="Menbership-Inderence"><a href="#Menbership-Inderence" class="headerlink" title="Menbership Inderence"></a>Menbership Inderence</h1><h2 id="Overview-of-the-attack"><a href="#Overview-of-the-attack" class="headerlink" title="Overview of the attack"></a>Overview of the attack</h2><p>Principle of utilization：“behave differently on the data that they were trained on versus the data that they “see” for the first time.” </p>
<p>Method: build multiple “shadow” models intended to behave similarly to the target model.So that we can know the ground truth for each shadow model.</p>
<h2 id="Shadow-models"><a href="#Shadow-models" class="headerlink" title="Shadow models"></a>Shadow models</h2><p>Here the type and structure of the target model are not known, but the attacker can use exactly the same service (e.g., Google Prediction API) to train the shadow model as was used to train the target model</p>
<p>“The more shadow models, the more accurate the attack model will be.” </p>
<h2 id="Generating-training-data-for-shadow-models"><a href="#Generating-training-data-for-shadow-models" class="headerlink" title="Generating training data for shadow models"></a>Generating training data for shadow models</h2><h3 id="Model-based-synthesis"><a href="#Model-based-synthesis" class="headerlink" title="Model-based synthesis"></a>Model-based synthesis</h3><p>Using hill-climbing algorithm</p>
<p><img src="C:\Users\梁韵扬\AppData\Local\Temp\b8623e22-0d80-40b2-838f-fe5752f0e1c9.png" alt="b8623e22-0d80-40b2-838f-fe5752f0e1c9"></p>
<h3 id="Statistics-based-synthesis"><a href="#Statistics-based-synthesis" class="headerlink" title="Statistics-based synthesis"></a>Statistics-based synthesis</h3><p> The attacker may have some statistical information about the population from which the target model’s training data was drawn</p>
<h3 id="Noisy-real-data"><a href="#Noisy-real-data" class="headerlink" title="Noisy real data"></a>Noisy real data</h3><p>The attacker may have access to some data that is similar to the target model’s training data and can be considered as a “noisy” version thereof.</p>
<h2 id="Training-the-attack-model"><a href="#Training-the-attack-model" class="headerlink" title="Training the attack model"></a>Training the attack model</h2><p>it learns to perform a much subtler task: how to distinguish between the training inputs classified with high confidence and other, non-training inputs that are also classified with high confidence.</p>
<h1 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h1><h2 id="data"><a href="#data" class="headerlink" title="data"></a>data</h2><p>image, purchase, locations, hospital stays, handwritten digits, census income.</p>
<h2 id="target-models"><a href="#target-models" class="headerlink" title="target models"></a>target models</h2><p>cloud-based service , neural networks</p>
<h2 id="Experimental-setup"><a href="#Experimental-setup" class="headerlink" title="Experimental setup"></a>Experimental setup</h2>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/06/27/Membership-Inference-Attacks-Against-Machine-Learning-Models/" data-id="cm1xui44l001nd8tgc9y0ea5b" data-title="Membership Inference Attacks Against Machine Learning Models" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning-attacks/" rel="tag">machine learning attacks</a></li></ul>

    </footer>
  </div>
  
</article>



  


  <nav id="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><a class="extend next" rel="next" href="/page/2/">weiter &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/algorithm-template/" rel="tag">algorithm-template</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ctf/" rel="tag">ctf</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ctf-misc/" rel="tag">ctf-misc</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/encryption/" rel="tag">encryption</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/machine-learning/" rel="tag">machine learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/machine-learning-attacks/" rel="tag">machine learning attacks</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/" rel="tag">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tip/" rel="tag">tip</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%AF%8F%E6%97%A5%E4%B8%80%E5%B0%8F%E7%BB%93/" rel="tag">每日一小结</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/algorithm-template/" style="font-size: 10px;">algorithm-template</a> <a href="/tags/ctf/" style="font-size: 20px;">ctf</a> <a href="/tags/ctf-misc/" style="font-size: 13.33px;">ctf-misc</a> <a href="/tags/encryption/" style="font-size: 13.33px;">encryption</a> <a href="/tags/machine-learning/" style="font-size: 16.67px;">machine learning</a> <a href="/tags/machine-learning-attacks/" style="font-size: 15px;">machine learning attacks</a> <a href="/tags/python/" style="font-size: 13.33px;">python</a> <a href="/tags/tip/" style="font-size: 11.67px;">tip</a> <a href="/tags/%E6%AF%8F%E6%97%A5%E4%B8%80%E5%B0%8F%E7%BB%93/" style="font-size: 18.33px;">每日一小结</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archiv</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/10/">October 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/09/">September 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/08/">August 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/07/">July 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/06/">June 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/05/">May 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/04/">April 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/03/">March 2024</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">letzter Beitrag</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2024/10/06/poison-attack-in-inductive-GNN/">poison attack in inductive GNN</a>
          </li>
        
          <li>
            <a href="/2024/09/28/Can-Graph-Neural-Networks-Be-Exploited-through-Data-Free-Model-Extraction-Attacks/">Can Graph Neural Networks Be Exploited through Data-Free Model Extraction Attacks?</a>
          </li>
        
          <li>
            <a href="/2024/09/23/Link-Stealing-Attacks-Against-Inductive-GNN/">Link Stealing Attacks Against Inductive GNN</a>
          </li>
        
          <li>
            <a href="/2024/08/09/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%BB%A3%E7%A0%81%EF%BC%9ANarcissus-tensflow/">深度学习代码：Narcissus/tensorflow</a>
          </li>
        
          <li>
            <a href="/2024/07/12/Stealing%20Links%20from%20GNN/">Stealing Links from GNN</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2024 tay<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>